{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SMS-Text-Classfier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "59bYVbOYvscJ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg27CNYtv02S",
        "outputId": "1783e0f7-7934-4d1e-ac58-4138662eacfe"
      },
      "source": [
        "# get data files\n",
        "TRAIN_DATA_URL = \"https://raw.githubusercontent.com/beaucarnes/fcc_python_curriculum/master/sms/train-data.tsv\"\n",
        "TEST_DATA_URL = \"https://raw.githubusercontent.com/beaucarnes/fcc_python_curriculum/master/sms/valid-data.tsv\"\n",
        "\n",
        "train_file_path = tf.keras.utils.get_file(\"train-data.tsv\", TRAIN_DATA_URL)\n",
        "test_file_path = tf.keras.utils.get_file(\"valid-data.tsv\", TEST_DATA_URL)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/beaucarnes/fcc_python_curriculum/master/sms/train-data.tsv\n",
            "360448/358233 [==============================] - 0s 0us/step\n",
            "368640/358233 [==============================] - 0s 0us/step\n",
            "Downloading data from https://raw.githubusercontent.com/beaucarnes/fcc_python_curriculum/master/sms/valid-data.tsv\n",
            "122880/118774 [===============================] - 0s 0us/step\n",
            "131072/118774 [=================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnAr7ODwv6Sq",
        "outputId": "d6f811cc-a4f3-4b0e-cf42-e71cdc7f4628"
      },
      "source": [
        "# convert data to pandas dataframe and change labels to numbers\n",
        "df_train = pd.read_csv(train_file_path,sep='\\t',header=None)\n",
        "df_test = pd.read_csv(test_file_path,sep='\\t',header=None)\n",
        "df_train[0] = df_train[0].replace(\"ham\", 0)\n",
        "df_train[0] = df_train[0].replace(\"spam\", 1)\n",
        "df_test[0] = df_test[0].replace(\"ham\", 0)\n",
        "df_test[0] = df_test[0].replace(\"spam\", 1)\n",
        "df_test[0]=df_test[0].astype('int64')\n",
        "df_train[0]=df_train[0].astype('int64')\n",
        "# convert data to TensorFlow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((df_train[1], df_train[0]))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((df_test[1], df_test[0]))\n",
        "# build vocab list\n",
        "\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tokenizer = tfds.deprecated.text.Tokenizer()\n",
        "\n",
        "vocabulary_set = set()\n",
        "for text_tensor, _ in train_dataset.concatenate(test_dataset):\n",
        "  some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
        "  vocabulary_set.update(some_tokens)\n",
        "\n",
        "vocab_size = len(vocabulary_set)\n",
        "vocab_size\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8741"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0gDVb5Xv653",
        "outputId": "8b374dfb-2e36-476b-86ff-7a2565ae5d99"
      },
      "source": [
        "# create encoder based on vocab list\n",
        "encoder = tfds.deprecated.text.TokenTextEncoder(vocabulary_set)\n",
        "# encode datasets\n",
        "def encode(text_tensor, label):\n",
        "  encoded_text = encoder.encode(text_tensor.numpy())\n",
        "  return encoded_text, label\n",
        "\n",
        "def encode_map_fn(text, label):\n",
        "  encoded_text, label = tf.py_function(encode, \n",
        "                                       inp=[text, label], \n",
        "                                       Tout=(tf.int64, tf.int64))\n",
        "  encoded_text.set_shape([None])\n",
        "  label.set_shape([])\n",
        "\n",
        "  return encoded_text, label\n",
        "\n",
        "\n",
        "train_dataset_encoded = train_dataset.map(encode_map_fn)\n",
        "test_dataset_encoded = test_dataset.map(encode_map_fn)\n",
        "# check what data looks like after encoding\n",
        "for train_example, train_label in train_dataset_encoded.take(2):\n",
        "  print('Encoded text:', train_example[:10].numpy())\n",
        "  print('Label:', train_label.numpy())\n",
        "\n",
        "# prepare data for training, padded_batch is used to make all reviews the same length while batching\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "train_batches = (\n",
        "    train_dataset_encoded\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .padded_batch(32))\n",
        "\n",
        "test_batches = (\n",
        "    test_dataset_encoded\n",
        "    .padded_batch(32))\n",
        "# build neural network model\n",
        "model = keras.Sequential([\n",
        "  keras.layers.Embedding(encoder.vocab_size, 16),\n",
        "  keras.layers.GlobalAveragePooling1D(),\n",
        "  keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded text: [8250 4205 3887 5283 4749 4464 1704 5182 6728 1345]\n",
            "Label: 0\n",
            "Encoded text: [6474 4369 4423 3862 3496]\n",
            "Label: 0\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 16)          139888    \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 16)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 139,905\n",
            "Trainable params: 139,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjzq_9nNv-_0",
        "outputId": "c58f5797-53be-4e64-acae-0346f8393c9a"
      },
      "source": [
        "# train model\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=10,\n",
        "                    validation_data=test_batches,\n",
        "                    validation_steps=30)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "131/131 [==============================] - 3s 17ms/step - loss: 0.5435 - accuracy: 0.8658 - val_loss: 0.4195 - val_accuracy: 0.8604\n",
            "Epoch 2/10\n",
            "131/131 [==============================] - 3s 17ms/step - loss: 0.3446 - accuracy: 0.8693 - val_loss: 0.3026 - val_accuracy: 0.8646\n",
            "Epoch 3/10\n",
            "131/131 [==============================] - 3s 16ms/step - loss: 0.2706 - accuracy: 0.8825 - val_loss: 0.2613 - val_accuracy: 0.8771\n",
            "Epoch 4/10\n",
            "131/131 [==============================] - 3s 17ms/step - loss: 0.2381 - accuracy: 0.8976 - val_loss: 0.2315 - val_accuracy: 0.8979\n",
            "Epoch 5/10\n",
            "131/131 [==============================] - 3s 17ms/step - loss: 0.2100 - accuracy: 0.9151 - val_loss: 0.2048 - val_accuracy: 0.9146\n",
            "Epoch 6/10\n",
            "131/131 [==============================] - 2s 16ms/step - loss: 0.1925 - accuracy: 0.9251 - val_loss: 0.1814 - val_accuracy: 0.9250\n",
            "Epoch 7/10\n",
            "131/131 [==============================] - 3s 17ms/step - loss: 0.1612 - accuracy: 0.9383 - val_loss: 0.1604 - val_accuracy: 0.9396\n",
            "Epoch 8/10\n",
            "131/131 [==============================] - 2s 16ms/step - loss: 0.1422 - accuracy: 0.9490 - val_loss: 0.1428 - val_accuracy: 0.9469\n",
            "Epoch 9/10\n",
            "131/131 [==============================] - 3s 16ms/step - loss: 0.1237 - accuracy: 0.9574 - val_loss: 0.1281 - val_accuracy: 0.9521\n",
            "Epoch 10/10\n",
            "131/131 [==============================] - 2s 17ms/step - loss: 0.1149 - accuracy: 0.9581 - val_loss: 0.1155 - val_accuracy: 0.9594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUazpMKRwBEz",
        "outputId": "73e8fd8a-9e21-4c09-a8c6-483752efee2e"
      },
      "source": [
        "# evaluate model\n",
        "loss, accuracy = model.evaluate(test_batches)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44/44 [==============================] - 1s 14ms/step - loss: 0.1196 - accuracy: 0.9555\n",
            "Loss:  0.11955641955137253\n",
            "Accuracy:  0.9554597735404968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZRPb2sbwDFt",
        "outputId": "c542f954-0a0f-4502-bb52-8e7a200b093f"
      },
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(pred_text):\n",
        "  encoded_pred_text = encoder.encode(pred_text)\n",
        "  encoded_pred_text = tf.cast(encoded_pred_text, tf.float32)\n",
        "  prediction = model.predict(tf.expand_dims(encoded_pred_text, tf.constant(0))).tolist()\n",
        "  prediction = prediction[0]\n",
        "  if prediction[0] < .5:\n",
        "    prediction.append(\"ham\")\n",
        "  else:\n",
        "    prediction.append(\"spam\")\n",
        "\n",
        "  return (prediction)\n",
        "\n",
        "pred_text = \"how are you doing today?\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.007641047239303589, 'ham']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xdxm1a9SwHVf",
        "outputId": "5650a1e5-fbf4-4090-cc34-6feeb8517f78"
      },
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won Â£1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You passed the challenge. Great job!\n"
          ]
        }
      ]
    }
  ]
}